{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bc584c-8d1f-48d0-9c71-c8c8ce19b704",
   "metadata": {},
   "source": [
    "1) a function named preprocess() that takes in a pandas.Series() of a corpus of text data as an argument. This function should output an indexed vocabulary and preprocessed tokens.\n",
    "2) a function named encode() that takes in two arguments: 1) a pandas.Series() (or the preprocessed token outputs of the preprocess() function), and 2) a specified encoding method. The function must include implementations for Bag-of-Words, TF-IDF, and Word2Vec. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd52bf93-e29a-4cac-acb5-3742713d9687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# import pandas as pd\n",
    "\n",
    "# Download the NLTK tokenizer models (only the first time)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess(corpus):\n",
    "    tokenized_corpus = []\n",
    "    for i, word in corpus.items():\n",
    "        tokenized_corpus.append(nltk.word_tokenize(word))\n",
    "    print(tokenized_corpus)\n",
    "    print([word for doc in tokenized_corpus for word in doc])\n",
    "    vocab = set()\n",
    "    for doc in tokenized_corpus:\n",
    "        for word in doc:\n",
    "            vocab.update(word)\n",
    "    return tokenized_corpus, vocab\n",
    "\n",
    "def encode(corpus, encoding_method):\n",
    "    if encoding_method == 'Bag-of-Words':\n",
    "        bow_vectorizer = CountVectorizer()\n",
    "        bow_matrix = bow_vectorizer.fit_transform(corpus)\n",
    "        print(bow_vectorizer.get_feature_names_out())\n",
    "        return bow_matrix.toarray()\n",
    "    \n",
    "    elif encoding_method == 'TF-IDF':\n",
    "        tdif_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = tdif_vectorizer.fit_transform(corpus)\n",
    "        print(tdif_vectorizer.get_feature_names_out())\n",
    "        return tfidf_matrix.toarray()\n",
    "    \n",
    "    elif encoding_method == 'Word2Vec':\n",
    "        model = Word2Vec([word_tokenize(doc) for doc in corpus], vector_size=20, window=5, min_count=1, workers=4)\n",
    "        #word_vectors = {word: model.wv[word] for word in model.wv.vocab}\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe2e5ed-27e9-4475-8dbd-f6eee6d7f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'], ['A', 'king', \"'s\", 'strength', 'also', 'includes', 'his', 'allies'], ['History', 'is', 'written', 'by', 'the', 'victors'], ['An', 'apple', 'a', 'day', 'keeps', 'the', 'doctor', 'away'], ['Nothing', 'happens', 'until', 'something', 'moves']]\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'A', 'king', \"'s\", 'strength', 'also', 'includes', 'his', 'allies', 'History', 'is', 'written', 'by', 'the', 'victors', 'An', 'apple', 'a', 'day', 'keeps', 'the', 'doctor', 'away', 'Nothing', 'happens', 'until', 'something', 'moves']\n",
      "['allies' 'also' 'an' 'apple' 'away' 'brown' 'by' 'day' 'doctor' 'dog'\n",
      " 'fox' 'happens' 'his' 'history' 'includes' 'is' 'jumps' 'keeps' 'king'\n",
      " 'lazy' 'moves' 'nothing' 'over' 'quick' 'something' 'strength' 'the'\n",
      " 'until' 'victors' 'written']\n",
      "Bag-of-Words Encoding:\n",
      "[[0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 2 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      " [0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0]]\n",
      "['allies' 'also' 'an' 'apple' 'away' 'brown' 'by' 'day' 'doctor' 'dog'\n",
      " 'fox' 'happens' 'his' 'history' 'includes' 'is' 'jumps' 'keeps' 'king'\n",
      " 'lazy' 'moves' 'nothing' 'over' 'quick' 'something' 'strength' 'the'\n",
      " 'until' 'victors' 'written']\n",
      "\n",
      "TF-IDF Encoding:\n",
      "[[0.         0.         0.         0.         0.         0.33721386\n",
      "  0.         0.         0.         0.33721386 0.33721386 0.\n",
      "  0.         0.         0.         0.         0.33721386 0.\n",
      "  0.         0.33721386 0.         0.         0.33721386 0.33721386\n",
      "  0.         0.         0.4516721  0.         0.         0.        ]\n",
      " [0.40824829 0.40824829 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40824829 0.         0.40824829 0.         0.         0.\n",
      "  0.40824829 0.         0.         0.         0.         0.\n",
      "  0.         0.40824829 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.42841136 0.         0.         0.         0.         0.\n",
      "  0.         0.42841136 0.         0.42841136 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.28691208 0.         0.42841136 0.42841136]\n",
      " [0.         0.         0.39379499 0.39379499 0.39379499 0.\n",
      "  0.         0.39379499 0.39379499 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.39379499\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26372909 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.4472136\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4472136  0.4472136  0.         0.\n",
      "  0.4472136  0.         0.         0.4472136  0.         0.        ]]\n",
      "\n",
      "Word2Vec Encoding:\n",
      "Word2Vec<vocab=34, vector_size=20, alpha=0.025>\n",
      "[('by', 0.46499761939048767), ('a', 0.40567827224731445), ('over', 0.36798784136772156), ('the', 0.31819355487823486), ('is', 0.29553940892219543)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CORPUS = pd.Series([\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"A king's strength also includes his allies\",\n",
    "    \"History is written by the victors\",\n",
    "    \"An apple a day keeps the doctor away\",\n",
    "    \"Nothing happens until something moves\"\n",
    "    ])\n",
    "TARGET = 'apple'\n",
    "\n",
    "vocabulary, tokenized_corpus = preprocess(CORPUS)\n",
    "\n",
    "# Encode using Bag-of-Words\n",
    "encoded_bow = encode(CORPUS, 'Bag-of-Words')\n",
    "print(\"Bag-of-Words Encoding:\")\n",
    "print(encoded_bow)\n",
    "\n",
    "# Encode using TF-IDF\n",
    "encoded_tfidf = encode(CORPUS, 'TF-IDF')\n",
    "print(\"\\nTF-IDF Encoding:\")\n",
    "print(encoded_tfidf)\n",
    "\n",
    "# Encode using Word2Vec\n",
    "encoded_word2vec = encode(CORPUS, 'Word2Vec')\n",
    "print(\"\\nWord2Vec Encoding:\")\n",
    "print(encoded_word2vec)\n",
    "print(encoded_word2vec.wv.most_similar(TARGET, topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc50a5-a59b-4168-aaa4-4ca7f1b09db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
